import os
import json
import math
from pathlib import Path
from llama_index.core import VectorStoreIndex, StorageContext, Settings
from llama_index.vector_stores.milvus import MilvusVectorStore
from llama_index.core.node_parser import SentenceSplitter
from llama_index.core import load_index_from_storage
from transformers import AutoTokenizer, AutoConfig
from .config import MILVUS_DB_PATH, EMBEDDING_MODEL, CHUNK_SIZE, CHUNK_OVERLAP, MILVUS_STORAGE, IF_IVFPQ
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from .utils import save_nodes, load_nodes
import logging

# åŸºæœ¬é…ç½®
logging.basicConfig(level=logging.INFO)
log = logging.info  # æˆ–è€…ä½¿ç”¨ logger

def init_embed_model():
    """åˆå§‹åŒ–åµŒå…¥æ¨¡å‹ã€‚"""
    Settings.embed_model = HuggingFaceEmbedding(
        model_name=EMBEDDING_MODEL,
        cache_folder=None,
        trust_remote_code=True,
        local_files_only=True
    )
    config = AutoConfig.from_pretrained(EMBEDDING_MODEL, trust_remote_code=True, local_files_only=True)
    return config.hidden_size


def calculate_nlist(vector_count):
    """
    æ ¹æ®å‘é‡æ•°é‡åŠ¨æ€è®¡ç®—èšç±»ä¸­å¿ƒæ•°

    Args:
        vector_count: å‘é‡æ•°é‡

    Returns:
        int: èšç±»ä¸­å¿ƒæ•° nlist
    """
    if vector_count <= 10000:
        num_cluster = max(1, vector_count // 50)  # ç¡®ä¿è‡³å°‘ä¸º1
    else:
        num_cluster = int(4 * math.sqrt(vector_count))

    # é™åˆ¶åœ¨åˆç†èŒƒå›´å†… [1, 65536]
    num_cluster = max(1, min(num_cluster, 65536))

    log(f"ğŸ“Š å‘é‡æ•°é‡: {vector_count}, è®¡ç®—å¾—åˆ°èšç±»ä¸­å¿ƒæ•° nlist={num_cluster}")
    return num_cluster


def create_milvus_vector_store(overwrite=True, vector_count=None):
    """
    åˆ›å»º Milvus å‘é‡å­˜å‚¨ã€‚

    Args:
        overwrite: æ˜¯å¦è¦†ç›–ç°æœ‰é›†åˆ
        vector_count: å‘é‡æ•°é‡ï¼Œç”¨äºåŠ¨æ€è®¡ç®— nlistï¼ˆä»…åœ¨ä½¿ç”¨ IVF_FLAT æ—¶éœ€è¦ï¼‰
    """
    abs_db_path = os.path.abspath(MILVUS_DB_PATH)
    if not os.path.exists(os.path.dirname(abs_db_path)):
        os.makedirs(os.path.dirname(abs_db_path))

    if int(IF_IVFPQ) == 1:
        # åŠ¨æ€è®¡ç®— nlist
        if vector_count is None:
            # å¦‚æœæ²¡æœ‰æä¾› vector_countï¼Œä½¿ç”¨é»˜è®¤å€¼
            nlist = 128
            log(f"âš ï¸  æœªæä¾›å‘é‡æ•°é‡ï¼Œä½¿ç”¨é»˜è®¤ nlist={nlist}")
        else:
            nlist = calculate_nlist(vector_count)

        # åŠ¨æ€è®¡ç®— nprobeï¼ˆå»ºè®®ä¸º nlist çš„ 5-10%ï¼‰
        nprobe = 10  # é™åˆ¶æœ€å¤§ä¸º64ä»¥ä¿è¯æ€§èƒ½

        index_config = {
            "index_type": "IVF_FLAT",
            "metric_type": "IP",
            "params": {
                "nlist": nlist
            }
        }

        search_config = {
            "params": {
                "nprobe": nprobe
            }
        }

        log(f"ğŸ”§ IVF_FLAT é…ç½®: nlist={nlist}, nprobe={nprobe}")

        return MilvusVectorStore(
            uri=abs_db_path,
            collection_name="rag_collection",
            dim=init_embed_model(),
            overwrite=overwrite,
            index_config=index_config,
            search_config=search_config
        ), index_config, search_config
    else:
        return MilvusVectorStore(
            uri=abs_db_path,
            collection_name="rag_collection",
            dim=init_embed_model(),
            overwrite=overwrite
        ), None, None


def build_index(documents, storage_context, milvus_config=None, reuse_nodes=None):
    """
    æ„å»ºå‘é‡ç´¢å¼•ã€‚

    Args:
        documents: æ–‡æ¡£åˆ—è¡¨
        storage_context: å­˜å‚¨ä¸Šä¸‹æ–‡
        milvus_config: Milvus é…ç½®ä¿¡æ¯ï¼ˆç”¨äºä¿å­˜ï¼‰
        reuse_nodes: é¢„å…ˆè§£æå¥½çš„èŠ‚ç‚¹ï¼ˆå¯é€‰ï¼Œé¿å…é‡å¤è§£æï¼‰
    """
    qwen_tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL, trust_remote_code=True)
    node_parser = SentenceSplitter(
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP,
        tokenizer=qwen_tokenizer.tokenize
    )

    # å¦‚æœæä¾›äº†é¢„è§£æçš„èŠ‚ç‚¹ï¼Œç›´æ¥ä½¿ç”¨
    if reuse_nodes is not None:
        nodes = reuse_nodes
        log(f"â™»ï¸  é‡ç”¨å·²è§£æçš„ {len(nodes)} ä¸ªèŠ‚ç‚¹")

        # ä»èŠ‚ç‚¹æ„å»ºç´¢å¼•
        index = VectorStoreIndex(
            nodes=nodes,
            storage_context=storage_context,
            embed_model=Settings.embed_model,
            # æ³¨æ„ï¼šä½¿ç”¨é¢„è§£æèŠ‚ç‚¹æ—¶ï¼Œä¸è¦è®¾ç½® store_nodes_override
            show_progress=True
        )
    else:
        # å¦åˆ™ä»æ–‡æ¡£æ„å»º
        index = VectorStoreIndex.from_documents(
            documents,
            storage_context=storage_context,
            embed_model=Settings.embed_model,
            transformations=[node_parser],
            store_nodes_override=True,
            show_progress=True
        )
        nodes = node_parser.get_nodes_from_documents(documents)

    # å°† milvus é…ç½®é™„åŠ åˆ° index å¯¹è±¡ä¸Šï¼Œä¾¿äºåç»­ä¿å­˜
    if milvus_config:
        index._milvus_config = milvus_config

    return index, nodes


def save_milvus_index(index, persist_dir):
    """ä¿å­˜ Milvus ç´¢å¼•åŠé…ç½®ã€‚"""
    persist_path = Path(persist_dir)
    persist_path.mkdir(parents=True, exist_ok=True)

    # ä¿å­˜ç´¢å¼•
    index.storage_context.persist(persist_dir=persist_dir)
    log(f"âœ… ç´¢å¼•å·²ä¿å­˜åˆ°: {persist_dir}")

    # ä¿å­˜ç´¢å¼•ä¿¡æ¯ï¼ˆåŒ…æ‹¬ IVF_FLAT é…ç½®ï¼‰
    index_info = {
        'collection_name': 'rag_collection',
        'milvus_db_path': MILVUS_DB_PATH,
        'embedding_dim': init_embed_model(),
        'total_documents': len(index.docstore.docs),
        'index_type': 'VectorStoreIndex',
        'use_ivf_flat': int(IF_IVFPQ) == 1,
    }

    # å¦‚æœä½¿ç”¨äº† IVF_FLATï¼Œä¿å­˜é…ç½®
    if hasattr(index, '_milvus_config'):
        index_info['milvus_index_config'] = index._milvus_config.get('index_config')
        index_info['milvus_search_config'] = index._milvus_config.get('search_config')
        log(f"âœ… IVF_FLAT é…ç½®å·²ä¿å­˜")

    info_file = persist_path / "index_info.json"
    with open(info_file, 'w', encoding='utf-8') as f:
        json.dump(index_info, f, ensure_ascii=False, indent=2)
    log(f"âœ… ç´¢å¼•ä¿¡æ¯å·²ä¿å­˜åˆ°: {info_file}")


def load_milvus_index(persist_dir, milvus_db_path=None):
    """åŠ è½½ Milvus ç´¢å¼•åŠé…ç½®ã€‚"""
    persist_path = Path(persist_dir)
    if not persist_path.exists():
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°ç´¢å¼•ç›®å½•: {persist_dir}")

    # è¯»å–ç´¢å¼•ä¿¡æ¯
    info_file = persist_path / "index_info.json"
    index_config = None
    search_config = None

    if info_file.exists():
        with open(info_file, 'r', encoding='utf-8') as f:
            index_info = json.load(f)

        milvus_db_path = milvus_db_path or index_info.get('milvus_db_path')
        use_ivf_flat = index_info.get('use_ivf_flat', False)

        # å¦‚æœä½¿ç”¨äº† IVF_FLATï¼ŒåŠ è½½é…ç½®
        if use_ivf_flat:
            index_config = index_info.get('milvus_index_config')
            search_config = index_info.get('milvus_search_config')
            if index_config and search_config:
                log(f"âœ… åŠ è½½ IVF_FLAT é…ç½®: nlist={index_config['params']['nlist']}, "
                      f"nprobe={search_config['params']['nprobe']}")

    # åˆ›å»º Milvus å‘é‡å­˜å‚¨
    if index_config and search_config:
        milvus_vector_store = MilvusVectorStore(
            uri=milvus_db_path,
            collection_name="rag_collection",
            dim=init_embed_model(),
            overwrite=False,
            index_config=index_config,
            search_config=search_config
        )
    else:
        milvus_vector_store = MilvusVectorStore(
            uri=milvus_db_path,
            collection_name="rag_collection",
            dim=init_embed_model(),
            overwrite=False
        )

    storage_context = StorageContext.from_defaults(
        vector_store=milvus_vector_store,
        persist_dir=persist_dir
    )

    index = load_index_from_storage(
        storage_context=storage_context,
        embed_model=Settings.embed_model
    )

    log(f"âœ… ç´¢å¼•å·²åŠ è½½")
    return index
