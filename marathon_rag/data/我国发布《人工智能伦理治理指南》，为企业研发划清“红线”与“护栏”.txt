本报北京电（记者 李哲）： 2025年9月15日，国家新一代人工智能治理专业委员会正式发布《人工智能伦理治理指南（试行）》（以下简称《指南》）。这是我国在人工智能治理领域的首份系统性、纲领性文件，旨在为快速发展的AI技术划定边界，推动负责任创新。

确立四大基本原则，构建治理框架
《指南》首次明确提出了人工智能发展应遵循的四大基本原则：
可控可信： 确保AI系统安全、可靠、可预测，防止失控风险，保障关键基础设施安全。
公平包容： 避免在数据采集、算法设计中产生歧视和偏见，保护未成年人、老年人等弱势群体的权益。
透明可释： 提高AI决策过程的透明度，确保在关键领域（如信贷审批、就业评估）的决策结果可追溯、可解释。
责任明确： 建立覆盖AI产品全生命周期的责任体系，明确研发者、提供者、使用者的各自责任。

聚焦高风险领域，提出具体监管要求
《指南》特别强调了对高风险AI应用的监管。要求在社会保障、司法决策、医疗诊断、金融风控、自动驾驶等公共服务和关键领域，建立严格的备案登记、数据溯源、算法审计和人工干预机制。例如，用于招聘的AI面试系统必须披露其核心评估维度，并允许候选人申诉复核。
对于生成式人工智能，《指南》要求深度合成（AIGC）服务提供者应对其生成内容进行显著标识，并禁止利用AI生成内容进行非法活动和社会欺诈。

企业回应与行业影响
《指南》的发布得到了科技企业的广泛响应。阿里巴巴、腾讯、百度等公司表示，将依据《指南》要求设立企业内部伦理审查委员会，并对现有产品进行合规性评估。有法律专家指出，《指南》虽为“试行”和“推荐性”标准，但为未来可能出台的强制性法规铺平了道路，企业尽早合规将有助于在激烈的市场竞争中赢得公众信任，规避潜在的法律风险。